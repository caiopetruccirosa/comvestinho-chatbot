{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d652b413",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Steps necessary to build a RAG based conversational model:\n",
    "1. Load documents\n",
    "2. Split documents\n",
    "3. Store documents\n",
    "4. Retrieve documents\n",
    "5. Generate answers based on retrieved documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9425a",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffccbc",
   "metadata": {},
   "source": [
    "## Necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a4612",
   "metadata": {},
   "source": [
    "To install necessary packages, run:\n",
    "\n",
    "```sh\n",
    "pip install openai==0.27.8\n",
    "pip install tiktoken\n",
    "pip install langchain\n",
    "pip install langchainhub\n",
    "pip install python-dotenv\n",
    "pip install chromadb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546baa2",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980bf1f8",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097efc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import dotenv\n",
    "\n",
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c858f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load OPENAI_API_KEY environment variable in .env file\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cdcef",
   "metadata": {},
   "source": [
    "## Creating embeddings and chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f3491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for model names\n",
    "CHAT_MODEL_NAME = 'gpt-3.5-turbo'\n",
    "EMBEDDINGS_MODEL_NAME = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79cd57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=CHAT_MODEL_NAME, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6db030",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=EMBEDDINGS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271911e3",
   "metadata": {},
   "source": [
    "## Loading Comvest data, processing and storing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e49ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AsyncHtmlLoader([\"https://www.pg.unicamp.br/norma/31594/0\"])\n",
    "html2text = Html2TextTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cc905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 750,\n",
    "    chunk_overlap = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8c6c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|###########################################################################################################| 1/1 [00:00<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752761e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_transformed = html2text.transform_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb5d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_splits = text_splitter.split_documents(docs_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a78f874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs_splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory='./vectorstore'\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e761ee",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86267d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE_TEMPLATE = \"\"\"Considere a conversa, o contexto e a pergunta dada para dar uma resposta. Caso você não saiba uma resposta, fale 'Me desculpe, mas não tenho uma resposta para esta pergunta' em vez de tentar inventar algo.\n",
    "----\n",
    "Conversa:\n",
    "{chat_history}\n",
    "----\n",
    "Contexto:\n",
    "{context}\n",
    "----\n",
    "\"\"\"\n",
    "\n",
    "HUMAN_MESSAGE_TEMPLATE = \"\"\"\n",
    "Pergunta:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(SYSTEM_MESSAGE_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(HUMAN_MESSAGE_TEMPLATE),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84e675",
   "metadata": {},
   "source": [
    "## Augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bd03c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(question, chat_history, retriever, prompt_template):\n",
    "    docs = retriever.get_relevant_documents(query=question)\n",
    "    \n",
    "    docs_formatted = '\\n'.join([doc.page_content for doc in docs])\n",
    "    chat_history_formatted = '\\n'.join([f\"Usuário: {exchange[0]}\\nSistema: {exchange[1]}\\n\" for exchange in chat_history])\n",
    "    \n",
    "    prompt = prompt_template.format_messages(\n",
    "        input_language=\"Portuguese\", \n",
    "        output_language=\"Portuguese\", \n",
    "        question=question,\n",
    "        context=docs_formatted,\n",
    "        chat_history=chat_history_formatted\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe96b1a",
   "metadata": {},
   "source": [
    "## Defining document retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa9828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee620c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVER_PROMPT_TEMPLATE = \"\"\"Você é um assistente de modelo de linguagem de IA. \n",
    "Sua tarefa é gerar 3 versões diferentes da pergunta do usuário fornecida para recuperar documentos relevantes de um banco de dados vetorial.\n",
    "Ao gerar múltiplas perspectivas sobre a pergunta do usuário, seu objetivo é ajudar o usuário a superar algumas das limitações da pesquisa de similaridade baseada em distância. \n",
    "Forneça estas perguntas alternativas separadas por novas linhas. \n",
    "Pergunta original: {question}\n",
    "\"\"\"\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\"), \n",
    "    llm=chat,\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=['question'], \n",
    "        template=RETRIEVER_PROMPT_TEMPLATE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921824be",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Como é o processo de inscrição pelo ENEM na Unicamp?\"\n",
    "\n",
    "docs = retriever_from_llm.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41cce6",
   "metadata": {},
   "source": [
    "## ChatBot demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e58e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = augment_prompt(\n",
    "    question=\"Como é o processo de inscrição pelo ENEM na Unicamp?\", \n",
    "    chat_history=[],\n",
    "    retriever=db_retriever, \n",
    "    prompt_template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51b7e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "682495ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O processo de inscrição pelo ENEM na Unicamp é realizado através da Comvest, que é responsável pela seleção de candidatos. As instruções necessárias para a inscrição, o Manual do Ingresso e as informações sobre a Unicamp e seus cursos estão disponíveis na página da Comvest (www.comvest.unicamp.br). Os candidatos isentos da Taxa de Inscrição serão dispensados do recolhimento dessa taxa. O processo de inscrição somente será validado com o recolhimento da Taxa de Inscrição. A situação da inscrição deverá ser consultada pelo candidato na página da Comvest a partir de 72 horas após a inscrição.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
